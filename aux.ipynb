{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a532387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = [\"low\" for i in range(5)]\n",
    "lower = [\"lower\" for i in range(2)]\n",
    "widest = [\"widest\" for i in range(3)]\n",
    "newest = [\"newest\" for i in range(6)]\n",
    "text = low + lower + widest + newest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7798031e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['low',\n",
       " 'low',\n",
       " 'low',\n",
       " 'low',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lower',\n",
       " 'widest',\n",
       " 'widest',\n",
       " 'widest',\n",
       " 'newest',\n",
       " 'newest',\n",
       " 'newest',\n",
       " 'newest',\n",
       " 'newest',\n",
       " 'newest']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5bcf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import os\n",
    "from multiprocessing import Pool,cpu_count\n",
    "import regex as re\n",
    "from cs336_basics.pretokenization_example import find_chunk_boundaries\n",
    "import time\n",
    "import json\n",
    "from collections import Counter,defaultdict\n",
    "import heapq\n",
    "\n",
    "def process_single_chunk(text):\n",
    "        words_to_count = Counter()\n",
    "\n",
    "        for t in text:\n",
    "\n",
    "            words_to_count[t] += 1\n",
    "        \n",
    "        words_to_tokens = {}\n",
    "        pair_to_words = defaultdict(set)\n",
    "        pair_to_count = Counter()\n",
    "        for word, count in words_to_count.items():\n",
    "            word_encoded = word.encode(\"utf-8\")\n",
    "            l_list = [bytes([b]) for b in word_encoded]\n",
    "            \n",
    "            words_to_tokens[word] = l_list\n",
    "            if len(l_list) >= 2:\n",
    "                for i in range(len(l_list) - 1):\n",
    "                    pair = (l_list[i], l_list[i + 1])\n",
    "                    pair_to_words[pair].add(word)\n",
    "                    pair_to_count[pair] += count\n",
    "        return {\n",
    "            \"words_to_count\": words_to_count,\n",
    "            \"words_to_tokens\": words_to_tokens,\n",
    "            \"pair_to_words\": pair_to_words,\n",
    "            \"pair_to_count\": pair_to_count\n",
    "        }\n",
    "        \n",
    "def pre_token(text):\n",
    "    chunk_results = []\n",
    "    chunk_results.append(process_single_chunk(text))\n",
    "    words_to_count = Counter()\n",
    "    pair_to_count = Counter()\n",
    "    words_to_tokens = {}\n",
    "    pair_to_words = defaultdict(set)\n",
    "    for chunk_result in chunk_results:\n",
    "        words_to_count.update(chunk_result[\"words_to_count\"])\n",
    "        pair_to_count.update(chunk_result[\"pair_to_count\"])\n",
    "        words_to_tokens.update(chunk_result[\"words_to_tokens\"])\n",
    "        for pair, word_set in chunk_result[\"pair_to_words\"].items():\n",
    "            pair_to_words[pair].update(word_set)\n",
    "\n",
    "    return {\n",
    "            \"words_to_count\": words_to_count,\n",
    "            \"words_to_tokens\": words_to_tokens,\n",
    "            \"pair_to_words\": pair_to_words,\n",
    "            \"pair_to_count\": pair_to_count\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d836f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pre_token(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc860db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words_to_count': Counter({'newest': 6, 'low': 5, 'widest': 3, 'lower': 2}),\n",
       " 'words_to_tokens': {'low': [b'l', b'o', b'w'],\n",
       "  'lower': [b'l', b'o', b'w', b'e', b'r'],\n",
       "  'widest': [b'w', b'i', b'd', b'e', b's', b't'],\n",
       "  'newest': [b'n', b'e', b'w', b'e', b's', b't']},\n",
       " 'pair_to_words': defaultdict(set,\n",
       "             {(b'l', b'o'): {'low', 'lower'},\n",
       "              (b'o', b'w'): {'low', 'lower'},\n",
       "              (b'w', b'e'): {'lower', 'newest'},\n",
       "              (b'e', b'r'): {'lower'},\n",
       "              (b'w', b'i'): {'widest'},\n",
       "              (b'i', b'd'): {'widest'},\n",
       "              (b'd', b'e'): {'widest'},\n",
       "              (b'e', b's'): {'newest', 'widest'},\n",
       "              (b's', b't'): {'newest', 'widest'},\n",
       "              (b'n', b'e'): {'newest'},\n",
       "              (b'e', b'w'): {'newest'}}),\n",
       " 'pair_to_count': Counter({(b'e', b's'): 9,\n",
       "          (b's', b't'): 9,\n",
       "          (b'w', b'e'): 8,\n",
       "          (b'l', b'o'): 7,\n",
       "          (b'o', b'w'): 7,\n",
       "          (b'n', b'e'): 6,\n",
       "          (b'e', b'w'): 6,\n",
       "          (b'w', b'i'): 3,\n",
       "          (b'i', b'd'): 3,\n",
       "          (b'd', b'e'): 3,\n",
       "          (b'e', b'r'): 2})}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199e2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseSortPair:\n",
    "    def __init__(self, pair):\n",
    "        self.pair = pair\n",
    "    def __lt__(self, other):\n",
    "        # 频率相同时，字典序大的返回 True (即它更“小”，会排在堆顶)\n",
    "        return self.pair > other.pair\n",
    "\n",
    "def train_bpe(text, vocab_size: int, special_tokens: List[str]) -> Tuple[Dict[int, bytes], List[Tuple[bytes, bytes]]]:\n",
    "    pre_token_result_dict = pre_token(text)\n",
    "    w2c = pre_token_result_dict[\"words_to_count\"]\n",
    "    w2t = pre_token_result_dict[\"words_to_tokens\"]\n",
    "    p2w = pre_token_result_dict[\"pair_to_words\"]\n",
    "    p2c = pre_token_result_dict[\"pair_to_count\"]\n",
    "    \n",
    "    # 先放special token（从ID 0开始），然后是256个字节\n",
    "    vocab = {}\n",
    "    for i, special_token in enumerate(special_tokens):\n",
    "        vocab[i] = special_token.encode(\"utf-8\")\n",
    "    for i in range(256):\n",
    "        vocab[len(special_tokens) + i] = bytes([i])\n",
    "    cur_vocab_size = 256 + len(special_tokens)\n",
    "    heap = [(-count, ReverseSortPair(pair)) for pair, count in p2c.items() if count > 0]\n",
    "    heapq.heapify(heap)\n",
    "    merges = []\n",
    "    while cur_vocab_size < vocab_size:\n",
    "        if not heap:\n",
    "            break\n",
    "        \n",
    "        neg_count, wrapper = heapq.heappop(heap)\n",
    "        best_pair = wrapper.pair\n",
    "        count = - neg_count\n",
    "        if count != p2c.get(best_pair,0):\n",
    "            continue\n",
    "        merges.append(best_pair)\n",
    "        words_to_update = list(p2w[best_pair])\n",
    "        new_token = best_pair[0] + best_pair[1]\n",
    "        vocab[cur_vocab_size] = new_token\n",
    "        cur_vocab_size += 1\n",
    "        for word in words_to_update:\n",
    "            new_tokens = []\n",
    "            old_tokens = w2t[word]\n",
    "            i = 0\n",
    "            while i < len(old_tokens):\n",
    "                if i < len(old_tokens) -1 and (old_tokens[i], old_tokens[i + 1]) == best_pair:\n",
    "                    new_tokens.append(new_token)\n",
    "                    if i > 0:\n",
    "                        # (old_token[i-1], old_token[i]) 这对pair 的count减去一个word count\n",
    "                        # p2w里面移除掉(old_token[i-1], old_token[i])对应的word\n",
    "                        # 生成新pair: (old_token[i], new_token)\n",
    "                        old_near_pair = (old_tokens[i - 1], old_tokens[i])\n",
    "                        p2c[old_near_pair] -= w2c[word]\n",
    "                        new_near_pair = (old_tokens[i -1], new_token)\n",
    "                        p2w[new_near_pair].add(word)\n",
    "                        if word in p2w[old_near_pair]:\n",
    "                            p2w[old_near_pair].remove(word)\n",
    "                        p2c[new_near_pair] += w2c[word]\n",
    "                        heapq.heappush(heap,(-p2c[new_near_pair], ReverseSortPair(new_near_pair)))\n",
    "                    if i < len(old_tokens) - 2:\n",
    "                        if (old_tokens[i + 1], old_tokens[i + 2]) != best_pair:\n",
    "                            old_near_pair = (old_tokens[i + 1], old_tokens[i + 2])\n",
    "                            p2c[old_near_pair] -= w2c[word]\n",
    "                            new_near_pair = (new_token, old_tokens[i + 2])\n",
    "                            p2w[new_near_pair].add(word)\n",
    "                            if word in p2w[old_near_pair]:\n",
    "                                p2w[old_near_pair].remove(word)\n",
    "                            p2c[new_near_pair] += w2c[word]\n",
    "                            heapq.heappush(heap,(-p2c[new_near_pair], ReverseSortPair(new_near_pair)))\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_tokens.append(old_tokens[i])\n",
    "                    i += 1\n",
    "            w2t[word] = new_tokens\n",
    "        del p2w[best_pair]\n",
    "        p2c[best_pair] = 0\n",
    "    \n",
    "    return vocab, merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aeb63d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: b'<|endoftext|>',\n",
       "  1: b'\\x00',\n",
       "  2: b'\\x01',\n",
       "  3: b'\\x02',\n",
       "  4: b'\\x03',\n",
       "  5: b'\\x04',\n",
       "  6: b'\\x05',\n",
       "  7: b'\\x06',\n",
       "  8: b'\\x07',\n",
       "  9: b'\\x08',\n",
       "  10: b'\\t',\n",
       "  11: b'\\n',\n",
       "  12: b'\\x0b',\n",
       "  13: b'\\x0c',\n",
       "  14: b'\\r',\n",
       "  15: b'\\x0e',\n",
       "  16: b'\\x0f',\n",
       "  17: b'\\x10',\n",
       "  18: b'\\x11',\n",
       "  19: b'\\x12',\n",
       "  20: b'\\x13',\n",
       "  21: b'\\x14',\n",
       "  22: b'\\x15',\n",
       "  23: b'\\x16',\n",
       "  24: b'\\x17',\n",
       "  25: b'\\x18',\n",
       "  26: b'\\x19',\n",
       "  27: b'\\x1a',\n",
       "  28: b'\\x1b',\n",
       "  29: b'\\x1c',\n",
       "  30: b'\\x1d',\n",
       "  31: b'\\x1e',\n",
       "  32: b'\\x1f',\n",
       "  33: b' ',\n",
       "  34: b'!',\n",
       "  35: b'\"',\n",
       "  36: b'#',\n",
       "  37: b'$',\n",
       "  38: b'%',\n",
       "  39: b'&',\n",
       "  40: b\"'\",\n",
       "  41: b'(',\n",
       "  42: b')',\n",
       "  43: b'*',\n",
       "  44: b'+',\n",
       "  45: b',',\n",
       "  46: b'-',\n",
       "  47: b'.',\n",
       "  48: b'/',\n",
       "  49: b'0',\n",
       "  50: b'1',\n",
       "  51: b'2',\n",
       "  52: b'3',\n",
       "  53: b'4',\n",
       "  54: b'5',\n",
       "  55: b'6',\n",
       "  56: b'7',\n",
       "  57: b'8',\n",
       "  58: b'9',\n",
       "  59: b':',\n",
       "  60: b';',\n",
       "  61: b'<',\n",
       "  62: b'=',\n",
       "  63: b'>',\n",
       "  64: b'?',\n",
       "  65: b'@',\n",
       "  66: b'A',\n",
       "  67: b'B',\n",
       "  68: b'C',\n",
       "  69: b'D',\n",
       "  70: b'E',\n",
       "  71: b'F',\n",
       "  72: b'G',\n",
       "  73: b'H',\n",
       "  74: b'I',\n",
       "  75: b'J',\n",
       "  76: b'K',\n",
       "  77: b'L',\n",
       "  78: b'M',\n",
       "  79: b'N',\n",
       "  80: b'O',\n",
       "  81: b'P',\n",
       "  82: b'Q',\n",
       "  83: b'R',\n",
       "  84: b'S',\n",
       "  85: b'T',\n",
       "  86: b'U',\n",
       "  87: b'V',\n",
       "  88: b'W',\n",
       "  89: b'X',\n",
       "  90: b'Y',\n",
       "  91: b'Z',\n",
       "  92: b'[',\n",
       "  93: b'\\\\',\n",
       "  94: b']',\n",
       "  95: b'^',\n",
       "  96: b'_',\n",
       "  97: b'`',\n",
       "  98: b'a',\n",
       "  99: b'b',\n",
       "  100: b'c',\n",
       "  101: b'd',\n",
       "  102: b'e',\n",
       "  103: b'f',\n",
       "  104: b'g',\n",
       "  105: b'h',\n",
       "  106: b'i',\n",
       "  107: b'j',\n",
       "  108: b'k',\n",
       "  109: b'l',\n",
       "  110: b'm',\n",
       "  111: b'n',\n",
       "  112: b'o',\n",
       "  113: b'p',\n",
       "  114: b'q',\n",
       "  115: b'r',\n",
       "  116: b's',\n",
       "  117: b't',\n",
       "  118: b'u',\n",
       "  119: b'v',\n",
       "  120: b'w',\n",
       "  121: b'x',\n",
       "  122: b'y',\n",
       "  123: b'z',\n",
       "  124: b'{',\n",
       "  125: b'|',\n",
       "  126: b'}',\n",
       "  127: b'~',\n",
       "  128: b'\\x7f',\n",
       "  129: b'\\x80',\n",
       "  130: b'\\x81',\n",
       "  131: b'\\x82',\n",
       "  132: b'\\x83',\n",
       "  133: b'\\x84',\n",
       "  134: b'\\x85',\n",
       "  135: b'\\x86',\n",
       "  136: b'\\x87',\n",
       "  137: b'\\x88',\n",
       "  138: b'\\x89',\n",
       "  139: b'\\x8a',\n",
       "  140: b'\\x8b',\n",
       "  141: b'\\x8c',\n",
       "  142: b'\\x8d',\n",
       "  143: b'\\x8e',\n",
       "  144: b'\\x8f',\n",
       "  145: b'\\x90',\n",
       "  146: b'\\x91',\n",
       "  147: b'\\x92',\n",
       "  148: b'\\x93',\n",
       "  149: b'\\x94',\n",
       "  150: b'\\x95',\n",
       "  151: b'\\x96',\n",
       "  152: b'\\x97',\n",
       "  153: b'\\x98',\n",
       "  154: b'\\x99',\n",
       "  155: b'\\x9a',\n",
       "  156: b'\\x9b',\n",
       "  157: b'\\x9c',\n",
       "  158: b'\\x9d',\n",
       "  159: b'\\x9e',\n",
       "  160: b'\\x9f',\n",
       "  161: b'\\xa0',\n",
       "  162: b'\\xa1',\n",
       "  163: b'\\xa2',\n",
       "  164: b'\\xa3',\n",
       "  165: b'\\xa4',\n",
       "  166: b'\\xa5',\n",
       "  167: b'\\xa6',\n",
       "  168: b'\\xa7',\n",
       "  169: b'\\xa8',\n",
       "  170: b'\\xa9',\n",
       "  171: b'\\xaa',\n",
       "  172: b'\\xab',\n",
       "  173: b'\\xac',\n",
       "  174: b'\\xad',\n",
       "  175: b'\\xae',\n",
       "  176: b'\\xaf',\n",
       "  177: b'\\xb0',\n",
       "  178: b'\\xb1',\n",
       "  179: b'\\xb2',\n",
       "  180: b'\\xb3',\n",
       "  181: b'\\xb4',\n",
       "  182: b'\\xb5',\n",
       "  183: b'\\xb6',\n",
       "  184: b'\\xb7',\n",
       "  185: b'\\xb8',\n",
       "  186: b'\\xb9',\n",
       "  187: b'\\xba',\n",
       "  188: b'\\xbb',\n",
       "  189: b'\\xbc',\n",
       "  190: b'\\xbd',\n",
       "  191: b'\\xbe',\n",
       "  192: b'\\xbf',\n",
       "  193: b'\\xc0',\n",
       "  194: b'\\xc1',\n",
       "  195: b'\\xc2',\n",
       "  196: b'\\xc3',\n",
       "  197: b'\\xc4',\n",
       "  198: b'\\xc5',\n",
       "  199: b'\\xc6',\n",
       "  200: b'\\xc7',\n",
       "  201: b'\\xc8',\n",
       "  202: b'\\xc9',\n",
       "  203: b'\\xca',\n",
       "  204: b'\\xcb',\n",
       "  205: b'\\xcc',\n",
       "  206: b'\\xcd',\n",
       "  207: b'\\xce',\n",
       "  208: b'\\xcf',\n",
       "  209: b'\\xd0',\n",
       "  210: b'\\xd1',\n",
       "  211: b'\\xd2',\n",
       "  212: b'\\xd3',\n",
       "  213: b'\\xd4',\n",
       "  214: b'\\xd5',\n",
       "  215: b'\\xd6',\n",
       "  216: b'\\xd7',\n",
       "  217: b'\\xd8',\n",
       "  218: b'\\xd9',\n",
       "  219: b'\\xda',\n",
       "  220: b'\\xdb',\n",
       "  221: b'\\xdc',\n",
       "  222: b'\\xdd',\n",
       "  223: b'\\xde',\n",
       "  224: b'\\xdf',\n",
       "  225: b'\\xe0',\n",
       "  226: b'\\xe1',\n",
       "  227: b'\\xe2',\n",
       "  228: b'\\xe3',\n",
       "  229: b'\\xe4',\n",
       "  230: b'\\xe5',\n",
       "  231: b'\\xe6',\n",
       "  232: b'\\xe7',\n",
       "  233: b'\\xe8',\n",
       "  234: b'\\xe9',\n",
       "  235: b'\\xea',\n",
       "  236: b'\\xeb',\n",
       "  237: b'\\xec',\n",
       "  238: b'\\xed',\n",
       "  239: b'\\xee',\n",
       "  240: b'\\xef',\n",
       "  241: b'\\xf0',\n",
       "  242: b'\\xf1',\n",
       "  243: b'\\xf2',\n",
       "  244: b'\\xf3',\n",
       "  245: b'\\xf4',\n",
       "  246: b'\\xf5',\n",
       "  247: b'\\xf6',\n",
       "  248: b'\\xf7',\n",
       "  249: b'\\xf8',\n",
       "  250: b'\\xf9',\n",
       "  251: b'\\xfa',\n",
       "  252: b'\\xfb',\n",
       "  253: b'\\xfc',\n",
       "  254: b'\\xfd',\n",
       "  255: b'\\xfe',\n",
       "  256: b'\\xff',\n",
       "  257: b'st',\n",
       "  258: b'est',\n",
       "  259: b'ow',\n",
       "  260: b'low',\n",
       "  261: b'west',\n",
       "  262: b'ne'},\n",
       " [(b's', b't'),\n",
       "  (b'e', b'st'),\n",
       "  (b'o', b'w'),\n",
       "  (b'l', b'ow'),\n",
       "  (b'w', b'est'),\n",
       "  (b'n', b'e')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = [\"<|endoftext|>\"]\n",
    "train_bpe(text, 263,special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d65c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

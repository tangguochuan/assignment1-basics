{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4299506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Transformer(\n",
       "  (embedding): Embedding()\n",
       "  (atten_layers): ModuleList(\n",
       "    (0-27): 28 x TransformerBlock(\n",
       "      (mha_layer): MHALayer(\n",
       "        (rms): RMSNorm()\n",
       "        (mhsa): MultiHeadSelfAttention(\n",
       "          (linear_q): Linear()\n",
       "          (linear_k): Linear()\n",
       "          (linear_v): Linear()\n",
       "          (linear_o): Linear()\n",
       "          (ScaledDotProductAttention): ScaledDotProductAttention(\n",
       "            (sm): SoftMax()\n",
       "          )\n",
       "          (rope): RotaryPositionalEmbedding()\n",
       "        )\n",
       "      )\n",
       "      (ffn_layer): FFNLayer(\n",
       "        (swiglu): SwiGLU(\n",
       "          (linear1): Linear()\n",
       "          (linear2): Linear()\n",
       "          (linear3): Linear()\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (rms): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (rms): RMSNorm()\n",
       "  (output_linear): Linear()\n",
       ")>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformer import Transformer\n",
    "\n",
    "model = Transformer(10000,128,28,4,512,100,10000)\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab907743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([0,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813acfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 2.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e956477c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data_ptr == a.sqrt().data_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7cf6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([0,4,4],dtype=torch.float32)\n",
    "a = torch.nn.Parameter(data=b, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f38b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
